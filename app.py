# app.py
# -*- coding: utf-8 -*-
"""
·ª®ng d·ª•ng Streamlit t·∫°o bi√™n b·∫£n cu·ªôc h·ªçp t·ª´ transcript (.docx) + Attendance (.csv/.xlsx).
- Gi·ªØ nguy√™n logic: validate b·∫Øt bu·ªôc, ƒëi·ªÅn template, g·ª≠i email.
- B·ªï sung:
    ‚Ä¢ Docling (n·∫øu c√≥): convert transcript .docx ‚Üí Markdown (fallback python-docx)
    ‚Ä¢ Attendance .csv/.xlsx: th·ª≠ Docling (n·∫øu c√≥/kh·∫£ d·ª•ng), fallback pandas ‚Üí bullets + b·∫£ng Markdown
    ‚Ä¢ H·ª£p nh·∫•t transcript + attendance v√†o prompt cho Gemini

Ch·∫°y:
    streamlit run app.py

G·ª£i √Ω requirements.txt:
    streamlit
    python-docx
    pandas
    openpyxl
    google-generativeai
    docling
"""

from __future__ import annotations
import io
import os
import re
import json
import zipfile
import ssl
import smtplib
import shutil
import tempfile
from typing import Dict, List, Optional, Tuple

import streamlit as st
import pandas as pd
from docx import Document
from docx.oxml import OxmlElement
from docx.text.paragraph import Paragraph
from docx.shared import Inches  # ƒë·ªÉ s·∫µn n·∫øu sau n√†y c·∫ßn ch√®n ·∫£nh
import google.generativeai as genai

# =========================
# C·∫§U H√åNH B·∫¢O M·∫¨T / API
# =========================
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    APP_EMAIL      = st.secrets["APP_EMAIL"]
    APP_PASSWORD   = st.secrets["APP_PASSWORD"]
except Exception:
    st.warning("Kh√¥ng t√¨m th·∫•y Streamlit Secrets. ƒêang d√πng c·∫•u h√¨nh local th·ª≠ nghi·ªám!")
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "YOUR_GEMINI_API_KEY")
    APP_EMAIL      = os.getenv("APP_EMAIL", "your_email@example.com")
    APP_PASSWORD   = os.getenv("APP_PASSWORD", "your_app_or_email_password")

try:
    genai.configure(api_key=GEMINI_API_KEY)
except Exception as e:
    st.error(f"L·ªói c·∫•u h√¨nh Gemini API: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i API Key.")

# =========================
# H·∫∞NG S·ªê & REGEX
# =========================
EMAIL_RE = re.compile(r"^[A-Za-z0-9._%+\-]+@[A-Za-z0-9.\-]+\.[A-Za-z]{2,}$")
REQUIRED_PLACEHOLDERS = ["TenCuocHop", "ThoiGianCuocHop", "DiaDiemCuocHop", "TenChuTri", "TenThuKy"]

COMMENT_RE     = re.compile(r"\{#.*?#\}")                # 1-run
COMMENT_ALL_RE = re.compile(r"\{#.*?#\}", re.DOTALL)     # ƒëa-run
BOLD_RE        = re.compile(r"\*\*(.*?)\*\*")            # **bold**
TOKEN_RE       = re.compile(r"\{\{([^{}]+)\}\}")         # {{Key}}

# =========================
# VALIDATE B·∫ÆT BU·ªòC
# =========================
def validate_inputs(
    template_option: str,
    transcript_file,
    template_file,
    meeting_name: str,
    meeting_time: str,
    meeting_location: str,
    meeting_chair: str,
    meeting_secretary: str,
    recipient_email: str,
    default_template_path: str = None
) -> bool:
    """
    Tr·∫£ v·ªÅ True n·∫øu h·ª£p l·ªá; ng∆∞·ª£c l·∫°i hi·ªÉn th·ªã th√¥ng b√°o ƒë·ªè v√† tr·∫£ v·ªÅ False.
    """
    missing = []

    # File b·∫Øt bu·ªôc
    if not transcript_file:
        missing.append("File transcript (.docx)")

    if template_option == "Template VPI":
        if default_template_path and not os.path.exists(default_template_path):
            missing.append(f"Template m·∫∑c ƒë·ªãnh kh√¥ng t·ªìn t·∫°i: {default_template_path}")
    elif template_option == "Template t√πy ch·ªânh":
        if not template_file:
            missing.append("File template t√πy ch·ªânh (.docx)")

    # Tr∆∞·ªùng b·∫Øt bu·ªôc
    if not meeting_name:
        missing.append("T√™n cu·ªôc h·ªçp")
    if not meeting_time:
        missing.append("Th·ªùi gian cu·ªôc h·ªçp")
    if not meeting_location:
        missing.append("ƒê·ªãa ƒëi·ªÉm cu·ªôc h·ªçp")
    if not meeting_chair:
        missing.append("T√™n ch·ªß tr√¨")
    if not meeting_secretary:
        missing.append("T√™n th∆∞ k√Ω")
    if not recipient_email:
        missing.append("Email nh·∫≠n k·∫øt qu·∫£")
    elif not EMAIL_RE.match(recipient_email.strip()):
        missing.append("Email nh·∫≠n k·∫øt qu·∫£ (kh√¥ng h·ª£p l·ªá)")

    if missing:
        st.error("‚ùå **Ch∆∞a ho√†n th√†nh th√¥ng tin**:\n\n- " + "\n- ".join(missing) +
                 "\n\nVui l√≤ng b·ªï sung/ƒë√≠nh k√®m ƒë·∫ßy ƒë·ªß r·ªìi b·∫•m l·∫°i **T·∫°o bi√™n b·∫£n**.")
        return False

    return True

# =========================
# UTILITIES: WORD/Paragraph
# =========================
def _is_md_table(text: str) -> bool:
    lines = [l.strip() for l in (text or "").strip().splitlines() if l.strip()]
    return (
        len(lines) >= 2
        and "|" in lines[0]
        and set(lines[1].replace(" ", "").replace(":", "")) <= set("-|")
    )

def _parse_md_table(text: str) -> Tuple[List[str], List[List[str]]]:
    lines  = [l.strip() for l in (text or "").strip().splitlines() if l.strip()]
    header = [c.strip() for c in lines[0].split("|")]
    if header and header[0] == "":
        header = header[1:]
    if header and header[-1] == "":
        header = header[:-1]
    rows: List[List[str]] = []
    for ln in lines[2:]:  # Skip header + separator
        cols = [c.strip() for c in ln.split("|")]
        if cols and cols[0] == "":
            cols = cols[1:]
        if cols and cols[-1] == "":
            cols = cols[:-1]
        if cols:
            while len(cols) > len(header):
                cols.pop()
            while len(cols) < len(header):
                cols.append("")
            rows.append(cols)
    return header, rows

def _insert_paragraph_after(anchor_para: Paragraph, style: Optional[str] = None) -> Paragraph:
    new_p_ox = OxmlElement("w:p")
    anchor_para._p.addnext(new_p_ox)
    new_para = Paragraph(new_p_ox, anchor_para._parent)
    if style:
        try:
            new_para.style = style
        except Exception:
            pass
    return new_para

def add_formatted_text(paragraph: Paragraph, text: str, style_info: Optional[dict] = None) -> None:
    parts   = BOLD_RE.split(text or "")
    is_bold = False
    for part in parts:
        if part == "":
            is_bold = not is_bold
            continue
        lines = part.split("\n")
        for i, ln in enumerate(lines):
            if i > 0:
                paragraph.add_run().add_break()
            if ln == "":
                continue
            run = paragraph.add_run(ln)
            if style_info:
                try:
                    f = run.font
                    if style_info.get("size"):
                        f.size = style_info["size"]
                    if style_info.get("name"):
                        f.name = style_info["name"]
                    if style_info.get("bold") is not None:
                        f.bold = style_info["bold"]
                    if style_info.get("italic") is not None:
                        f.italic = style_info["italic"]
                except Exception:
                    pass
            run.bold = run.bold or is_bold
        is_bold = not is_bold

def _concat_runs(paragraph: Paragraph) -> Tuple[str, List[Tuple]]:
    meta, pos, buf = [], 0, []
    for r in paragraph.runs:
        t = r.text or ""
        start, end = pos, pos + len(t)
        meta.append((r, start, end))
        buf.append(t)
        pos = end
    return "".join(buf), meta

def _insert_table_after(paragraph: Paragraph, header: List[str], rows: List[List[str]], table_style: str = "New Table") -> None:
    if not header or not rows:
        return
    body = paragraph._parent
    tbl  = body.add_table(rows=len(rows)+1, cols=len(header))
    try:
        tbl.style = table_style
    except Exception:
        pass
    for i, h in enumerate(header):
        try:
            tbl.rows[0].cells[i].text = str(h)
        except Exception:
            pass
    for r_idx, row in enumerate(rows, start=1):
        for c_idx, cell_val in enumerate(row):
            try:
                tbl.rows[r_idx].cells[c_idx].text = str(cell_val)
            except Exception:
                pass
    paragraph._p.addnext(tbl._tbl)

# =========================
# WORD TEMPLATE PROCESSING
# =========================
def extract_vars_and_desc(docx_file_or_buffer) -> Dict[str, str]:
    """Tr√≠ch xu·∫•t {placeholder: m√¥ t·∫£} t·ª´ .docx (body/header/footer)."""
    xml_parts: List[str] = []
    with zipfile.ZipFile(docx_file_or_buffer) as z:
        for name in z.namelist():
            if name.startswith("word/") and name.endswith(".xml"):
                xml_parts.append(z.read(name).decode("utf8"))
    all_xml = "\n".join(xml_parts)
    texts = re.findall(r"<w:t[^>]*>(.*?)</w:t>", all_xml, flags=re.DOTALL)
    full_text = "".join(texts)
    pattern = re.compile(r"\{\{\s*([A-Za-z0-9_]+)\s*\}\}\s*\{#\s*(.*?)\s*#\}", flags=re.DOTALL)
    return dict(pattern.findall(full_text))

def replace_in_paragraph(paragraph: Paragraph, data: Dict[str, str]) -> None:
    if not paragraph.runs:
        return
    full_text, meta = _concat_runs(paragraph)
    if not full_text:
        return

    items = []
    for m in COMMENT_ALL_RE.finditer(full_text):
        items.append(("comment", m.start(), m.end(), None))
    for m in TOKEN_RE.finditer(full_text):
        key = (m.group(1) or "").strip()
        if key in data:
            items.append(("token", m.start(), m.end(), key))

    if not items:
        for r in paragraph.runs:
            if r.text and COMMENT_RE.search(r.text):
                r.text = COMMENT_RE.sub("", r.text)
        return

    items.sort(key=lambda x: x[1], reverse=True)

    bullet_queue: List[Tuple[str, str]] = []  # (text, style)
    table_queue:  List[Tuple[List[str], List[List[str]]]] = []

    for item_type, start, end, key in items:
        run_start_idx = next((i for i, (_, s, e) in enumerate(meta) if s <= start < e), None)
        run_end_idx   = next((i for i, (_, s, e) in enumerate(meta) if s <  end <= e), None)
        if run_start_idx is None or run_end_idx is None:
            continue

        run_start, s0, e0 = meta[run_start_idx]
        run_end,   s1, e1 = meta[run_end_idx]
        offset_start = start - s0
        offset_end   = end   - s1

        if item_type == "comment":
            if run_start_idx == run_end_idx:
                t = run_start.text or ""
                run_start.text = t[:offset_start] + t[offset_end:]
            else:
                run_start.text = (run_start.text or "")[:offset_start]
                for i in range(run_start_idx + 1, run_end_idx):
                    meta[i][0].text = ""
                run_end.text = (run_end.text or "")[offset_end:]
            continue

        value = data.get(key, "")

        if isinstance(value, str) and _is_md_table(value):
            try:
                header, rows = _parse_md_table(value)
                table_queue.append((header, rows))
                if run_start_idx == run_end_idx:
                    t = run_start.text or ""
                    run_start.text = t[:offset_start] + t[offset_end:]
                else:
                    run_start.text = (run_start.text or "")[:offset_start]
                    for i in range(run_start_idx + 1, run_end_idx):
                        meta[i][0].text = ""
                    run_end.text = (run_end.text or "")[offset_end:]
                continue
            except Exception:
                value = str(value)

        if isinstance(value, str) and any(line.strip().startswith(("-", "+")) for line in value.splitlines()):
            for line in value.splitlines():
                s = line.strip()
                if s.startswith("-"):
                    bullet_queue.append((s[1:].strip(), "List Bullet"))
                elif s.startswith("+"):
                    bullet_queue.append((s[1:].strip(), "List Bullet 2"))
            if run_start_idx == run_end_idx:
                t = run_start.text or ""
                run_start.text = t[:offset_start] + t[offset_end:]
            else:
                run_start.text = (run_start.text or "")[:offset_start]
                for i in range(run_start_idx + 1, run_end_idx):
                    meta[i][0].text = ""
                run_end.text = (run_end.text or "")[offset_end:]
            continue

        replacement_text = str(value)
        if run_start_idx == run_end_idx:
            t = run_start.text or ""
            run_start.text = t[:offset_start] + replacement_text + t[offset_end:]
        else:
            for i in range(run_start_idx + 1, run_end_idx):
                meta[i][0].text = ""
            start_text = (run_start.text or "")[:offset_start]
            run_start.text = start_text + replacement_text
            run_end.text = (run_end.text or "")[offset_end:]

    if bullet_queue or table_queue:
        current_para = paragraph
        for text, style in bullet_queue:
            current_para = _insert_paragraph_after(current_para, style=style)
            add_formatted_text(current_para, text)
        for header, rows in table_queue:
            try:
                _insert_table_after(current_para, header, rows)
            except Exception as e:
                print(f"Error inserting table: {e}")

def fill_template_to_buffer(template_file_or_path, data_input: Dict[str, str]) -> Optional[io.BytesIO]:
    try:
        doc = Document(template_file_or_path)
    except Exception as e:
        st.error(f"L·ªói m·ªü template: {e}")
        return None

    for i, paragraph in enumerate(doc.paragraphs):
        try:
            replace_in_paragraph(paragraph, data_input)
        except Exception as e:
            print(f"Error processing paragraph {i}: {e}")

    for table_idx, table in enumerate(doc.tables):
        for row_idx, row in enumerate(table.rows):
            for cell_idx, cell in enumerate(row.cells):
                for para_idx, paragraph in enumerate(cell.paragraphs):
                    try:
                        replace_in_paragraph(paragraph, data_input)
                    except Exception as e:
                        print(f"Error processing table {table_idx}, row {row_idx}, cell {cell_idx}, paragraph {para_idx}: {e}")

    for section in doc.sections:
        if section.header:
            for paragraph in section.header.paragraphs:
                try:
                    replace_in_paragraph(paragraph, data_input)
                except Exception as e:
                    print(f"Error processing header paragraph: {e}")
        if section.footer:
            for paragraph in section.footer.paragraphs:
                try:
                    replace_in_paragraph(paragraph, data_input)
                except Exception as e:
                    print(f"Error processing footer paragraph: {e}")

    try:
        buf = io.BytesIO()
        doc.save(buf)
        buf.seek(0)
        return buf
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói khi t·∫°o file Word: {e}")
        return None

# =========================
# DOCLING + ATTENDANCE
# =========================
def extract_transcript_markdown(transcript_file) -> str:
    """
    ∆Øu ti√™n Docling ƒë·ªÉ convert .docx ‚Üí Markdown.
    N·∫øu l·ªói/kh√¥ng c√≥ Docling ‚Üí fallback python-docx ‚Üí Markdown t·ªëi gi·∫£n.
    """
    tmp_path = None
    try:
        try:
            from docling.document_converter import DocumentConverter
        except Exception:
            raise ImportError("Docling not available")

        suffix = os.path.splitext(getattr(transcript_file, "name", "") or "")[1] or ".docx"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp_path = tmp.name
            transcript_file.seek(0)
            shutil.copyfileobj(transcript_file, tmp)

        conv = DocumentConverter()
        res  = conv.convert(tmp_path)
        md   = res.document.export_markdown() if hasattr(res.document, "export_markdown") \
               else res.document.export_to_markdown()
        return (md or "").strip()

    except Exception:
        # Fallback python-docx
        try:
            transcript_file.seek(0)
        except Exception:
            pass
        try:
            doc = Document(transcript_file)
            text = "\n".join(p.text for p in doc.paragraphs)
            return ("## Transcript (fallback Docx)\n\n" + text).strip()
        except Exception as ee:
            st.error(f"L·ªói ƒë·ªçc transcript: {ee}")
            return ""
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try: os.remove(tmp_path)
            except Exception: pass

def _normalize(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s2 = s.strip().lower()
    rep = {
        "√†":"a","√°":"a","·∫£":"a","√£":"a","·∫°":"a","ƒÉ":"a","·∫±":"a","·∫Ø":"a","·∫≥":"a","·∫µ":"a","·∫∑":"a",
        "√¢":"a","·∫ß":"a","·∫•":"a","·∫©":"a","·∫´":"a","·∫≠":"a","√®":"e","√©":"e","·∫ª":"e","·∫Ω":"e","·∫π":"e",
        "√™":"e","·ªÅ":"e","·∫ø":"e","·ªÉ":"e","·ªÖ":"e","·ªá":"e","√¨":"i","√≠":"i","·ªâ":"i","ƒ©":"i","·ªã":"i",
        "√≤":"o","√≥":"o","·ªè":"o","√µ":"o","·ªç":"o","√¥":"o","·ªì":"o","·ªë":"o","·ªï":"o","·ªó":"o","·ªô":"o",
        "∆°":"o","·ªù":"o","·ªõ":"o","·ªü":"o","·ª°":"o","·ª£":"o","√π":"u","√∫":"u","·ªß":"u","≈©":"u","·ª•":"u",
        "∆∞":"u","·ª´":"u","·ª©":"u","·ª≠":"u","·ªØ":"u","·ª±":"u","·ª≥":"y","√Ω":"y","·ª∑":"y","·ªπ":"y","·ªµ":"y",
        "ƒë":"d"
    }
    for a, b in rep.items():
        s2 = s2.replace(a, b)
    return s2

def _first_match(cols: List[str], candidates: List[str]) -> Optional[str]:
    cols_norm = {c: _normalize(c) for c in cols}
    for cand in candidates:
        for col, norm in cols_norm.items():
            if cand in norm:
                return col
    return None

def _looks_present(val) -> bool:
    if val is None:
        return True
    s = str(val).strip().lower()
    return s in {"1","x","‚úì","yes","y","true","present","co","c√≥","tham du","attended"}

def attendance_df_to_struct(df: pd.DataFrame) -> Dict[str, str]:
    """Bi·∫øn df attendance ‚Üí bullets + b·∫£ng Markdown."""
    if df is None or df.empty:
        return {"participants_bullets":"", "participants_table_md":""}

    cols = list(df.columns)
    name_col = _first_match(cols, ["name","full name","fullname","ho va ten","ho ten","ten","h·ªç v√† t√™n"])
    role_col = _first_match(cols, ["role","vai tro","chuc vu","title","position"])
    mail_col = _first_match(cols, ["email","mail"])
    dept_col = _first_match(cols, ["department","phong ban","don vi","unit","division"])
    att_col  = _first_match(cols, ["attendance","status","co mat","tham du","present","attended"])

    if att_col:
        df = df[df[att_col].apply(_looks_present)]

    # Bullets c·∫•p 2
    bullets = []
    for _, r in df.iterrows():
        name = str(r.get(name_col, "")).strip()
        role = str(r.get(role_col, "")).strip()
        dept = str(r.get(dept_col, "")).strip()
        mail = str(r.get(mail_col, "")).strip()
        info = name
        tail = ", ".join([x for x in [role, dept] if x])
        if tail: info += f" ‚Äî {tail}"
        if mail: info += f" ({mail})"
        if info:
            bullets.append(f"+ {info}")
    participants_bullets = "\n".join(bullets)

    # B·∫£ng Markdown
    headers = []; rows = []
    def add_hdr(h):
        if h not in headers: headers.append(h)
    if name_col: add_hdr("Name")
    if role_col: add_hdr("Role/Title")
    if dept_col: add_hdr("Department")
    if mail_col: add_hdr("Email")
    if headers:
        for _, r in df.iterrows():
            row=[]
            if name_col: row.append(str(r.get(name_col,"")).strip())
            if role_col: row.append(str(r.get(role_col,"")).strip())
            if dept_col: row.append(str(r.get(dept_col,"")).strip())
            if mail_col: row.append(str(r.get(mail_col,"")).strip())
            rows.append(row)
        sep = "|" + "|".join(["---"]*len(headers)) + "|"
        table_md = "|" + "|".join(headers) + "|\n" + sep + "\n" + "\n".join(["|" + "|".join(r) + "|" for r in rows])
    else:
        table_md = ""

    return {
        "participants_bullets": participants_bullets,
        "participants_table_md": table_md,
    }

def attendance_via_docling(attendance_file) -> Optional[str]:
    """Th·ª≠ convert attendance b·∫±ng Docling ‚Üí Markdown (n·∫øu h·ªó tr·ª£). Kh√¥ng ƒë·∫£m b·∫£o cho CSV/XLSX."""
    tmp_path = None
    try:
        try:
            from docling.document_converter import DocumentConverter
        except Exception:
            return None
        suffix = os.path.splitext(getattr(attendance_file, "name","") or "")[1] or ".csv"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp_path = tmp.name
            attendance_file.seek(0)
            shutil.copyfileobj(attendance_file, tmp)
        conv = DocumentConverter()
        res  = conv.convert(tmp_path)
        md = res.document.export_markdown() if hasattr(res.document, "export_markdown") \
             else res.document.export_to_markdown()
        return (md or "").strip() or None
    except Exception:
        return None
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try: os.remove(tmp_path)
            except Exception: pass

def attendance_file_to_markdown(attendance_file) -> str:
    """
    Pipeline ƒë·ªçc attendance:
    1) Th·ª≠ Docling ‚Üí Markdown
    2) Fallback pandas ‚Üí bullets + b·∫£ng Markdown
    """
    if not attendance_file:
        return ""

    # Docling tr∆∞·ªõc
    md = attendance_via_docling(attendance_file)
    if md:
        return ("## Attendance (Docling)\n\n" + md).strip()

    # Fallback pandas
    try:
        attendance_file.seek(0)
    except Exception:
        pass

    name = getattr(attendance_file, "name", "") or ""
    ext = os.path.splitext(name.lower())[1]
    try:
        if ext in (".xlsx", ".xls"):
            df = pd.read_excel(attendance_file)
        else:
            last_err = None
            for enc in ["utf-8","utf-8-sig","cp1258","latin1"]:
                try:
                    attendance_file.seek(0)
                except Exception:
                    pass
                try:
                    df = pd.read_csv(attendance_file, encoding=enc)
                    break
                except Exception as e:
                    last_err = e
            else:
                raise last_err or RuntimeError("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c CSV.")
    except Exception as e:
        st.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc attendance b·∫±ng pandas: {e}")
        return ""

    struct = attendance_df_to_struct(df)
    bullets = struct.get("participants_bullets","").strip()
    tablemd = struct.get("participants_table_md","").strip()
    mk = ["## Attendance (normalized)"]
    if bullets:
        mk.append("\n### Participants (bullets)\n" + bullets)
    if tablemd:
        mk.append("\n### Participants (table)\n" + tablemd)
    return "\n".join(mk).strip()

# =========================
# LLM (Gemini)
# =========================
def call_gemini_model(transcript_markdown: str, placeholders: Dict[str, str], attendance_markdown: str = "") -> Optional[Dict[str, str]]:
    model = genai.GenerativeModel("gemini-2.5-pro")

    unified_md = f"""
# SOURCE PACKET
## 1) TRANSCRIPT (Markdown)
{transcript_markdown}

## 2) ATTENDANCE (Markdown)
{attendance_markdown or '*(Kh√¥ng c√≥ file attendance ƒë∆∞·ª£c cung c·∫•p)*'}
""".strip()

    Prompt_word = f"""
# Vai tr√≤
B·∫°n l√† tr·ª£ l√Ω AI chuy√™n nghi·ªáp, c√≥ nhi·ªám v·ª• tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng t·ª´ *SOURCE PACKET* b√™n d∆∞·ªõi ƒë·ªÉ t·∫°o n·ªôi dung cho bi√™n b·∫£n cu·ªôc h·ªçp (ti·∫øng Vi·ªát, vƒÉn phong trang tr·ªçng).

# SOURCE PACKET (Markdown)
{unified_md}

# Placeholders (dict: key = t√™n tr∆∞·ªùng, value = m√¥ t·∫£/ƒë·ªãnh d·∫°ng):
```json
{json.dumps(placeholders, ensure_ascii=False)}
```

# Y√™u c·∫ßu xu·∫•t
- **Ch·ªâ tr·∫£ v·ªÅ 1 JSON h·ª£p l·ªá duy nh·∫•t**.
- **Keys tr√πng 100%** v·ªõi placeholders (kh√¥ng th√™m/b·ªõt/ƒë·ªïi ki·ªÉu ch·ªØ).
- **M·ªçi value l√† chu·ªói**.
- Tu√¢n th·ªß **ƒë·ªãnh d·∫°ng trong m√¥ t·∫£**: bullet 1 "- ", bullet 2 "+ ", b·∫£ng Markdown...
- N·∫øu thi·∫øu th√¥ng tin ‚Üí ƒëi·ªÅn ƒë√∫ng chu·ªói **"Ch∆∞a c√≥ th√¥ng tin"**.

# K·∫øt qu·∫£
Tr·∫£ v·ªÅ 1 chu·ªói JSON duy nh·∫•t, kh√¥ng k√®m gi·∫£i th√≠ch.
"""

    try:
        response = model.generate_content(
            contents=Prompt_word,
            generation_config={"response_mime_type": "application/json"}
        )
        if response and hasattr(response, "text"):
            raw = response.text.strip()
            if raw.startswith("```"):
                raw = raw.split("```")[1].strip("json\n")
            return json.loads(raw)
        else:
            st.error("Ph·∫£n h·ªìi t·ª´ Gemini API b·ªã thi·∫øu ho·∫∑c kh√¥ng h·ª£p l·ªá.")
            return None
    except Exception as e:
        st.error(f"L·ªói khi g·ªçi Gemini API: {e}")
        return None

# =========================
# EMAIL
# =========================
def send_email_with_attachment(recipient_email: str, attachment_buffer: io.BytesIO, filename: str = "Bien_ban_cuoc_hop.docx") -> bool:
    SMTP_SERVER = "smtp.office365.com"
    SMTP_PORT = 587
    from email.message import EmailMessage

    msg = EmailMessage()
    msg["Subject"] = "Bi√™n b·∫£n cu·ªôc h·ªçp ƒë√£ ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông"
    msg["From"] = APP_EMAIL
    msg["To"] = recipient_email
    msg.set_content(
        "Ch√†o b·∫°n,\n\nBi√™n b·∫£n cu·ªôc h·ªçp ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng.\nVui l√≤ng xem trong file ƒë√≠nh k√®m.\n\nTr√¢n tr·ªçng,\nC√¥ng c·ª• t·∫°o bi√™n b·∫£n t·ª± ƒë·ªông."
    )
    msg.add_attachment(
        attachment_buffer.getvalue(),
        maintype="application",
        subtype="vnd.openxmlformats-officedocument.wordprocessingml.document",
        filename=filename,
    )

    try:
        ctx = ssl.create_default_context()
        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as s:
            s.starttls(context=ctx)
            s.login(APP_EMAIL, APP_PASSWORD)
            s.send_message(msg)
        return True
    except Exception as e:
        st.error(f"L·ªói khi g·ª≠i email: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh email v√† m·∫≠t kh·∫©u ·ª©ng d·ª•ng.")
        return False

# =========================
# HELPERS (IO)
# =========================
def ensure_template_path(default_filename: str) -> Optional[str]:
    """Tr·∫£ template path n·∫øu t·ªìn t·∫°i, ng∆∞·ª£c l·∫°i c·∫£nh b√°o ng∆∞·ªùi d√πng ch·ªçn custom."""
    if os.path.exists(default_filename):
        return default_filename
    st.error(f"Kh√¥ng t√¨m th·∫•y template m·∫∑c ƒë·ªãnh: {default_filename}. H√£y ch·ªçn 'Template t√πy ch·ªânh' v√† t·∫£i file l√™n.")
    return None

def to_bytesio(file_or_path):
    """ƒê∆∞a template (path ho·∫∑c UploadedFile) v·ªÅ BytesIO ƒë·ªÉ d√πng l·∫∑p nhi·ªÅu l·∫ßn."""
    if isinstance(file_or_path, (str, os.PathLike)):
        with open(file_or_path, "rb") as f:
            return io.BytesIO(f.read())
    else:
        try:
            file_or_path.seek(0)
        except Exception:
            pass
        return io.BytesIO(file_or_path.read())

# =========================
# STREAMLIT UI
# =========================
st.set_page_config(layout="wide", page_title="C√¥ng c·ª• t·∫°o Bi√™n b·∫£n cu·ªôc h·ªçp")
st.title("üõ†Ô∏è C√¥ng c·ª• t·∫°o bi√™n b·∫£n cu·ªôc h·ªçp t·ª± ƒë·ªông")

with st.sidebar:
    st.info("üìù **H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng**")
    st.markdown("""
1. **T·∫£i transcript (.docx)** v√† *(tu·ª≥ ch·ªçn)* **attendance (.csv/.xlsx)**.
2. **Ch·ªçn Template:** "Template VPI" ho·∫∑c "Template tu·ª≥ ch·ªânh (.docx)".
3. **ƒêi·ªÅn th√¥ng tin b·∫Øt bu·ªôc** (T√™n h·ªçp, Th·ªùi gian, ƒê·ªãa ƒëi·ªÉm, Ch·ªß tr√¨, Th∆∞ k√Ω, Email).
4. Nh·∫•n **T·∫°o bi√™n b·∫£n**.
    """)
    st.info("üß© **T·∫°o template** ‚Äî d√πng {{Ten_bien}}{# m√¥ t·∫£ #} cho c√°c tr∆∞·ªùng tr√≠ch xu·∫•t. B·∫£ng d√πng Markdown, bullet: '- ' v√† '+ '.")

st.subheader("1. Nh·∫≠p th√¥ng tin ƒë·∫ßu v√†o")
col_in_1, col_in_2 = st.columns(2)
with col_in_1:
    transcript_file = st.file_uploader("T·∫£i transcript (.docx) ‚Äî b·∫Øt bu·ªôc", type=["docx"])
with col_in_2:
    attendance_file = st.file_uploader("Attendance (.csv/.xlsx) ‚Äî tu·ª≥ ch·ªçn", type=["csv","xlsx","xls"])

st.subheader("2. L·ª±a ch·ªçn Template")
template_option = st.selectbox(
    "B·∫°n mu·ªën s·ª≠ d·ª•ng lo·∫°i template n√†o?",
    ("Template VPI", "Template t√πy ch·ªânh"),
    help="Ch·ªçn 'Template VPI' ƒë·ªÉ d√πng m·∫´u c√≥ s·∫µn ho·∫∑c 'Template t√πy ch·ªânh' ƒë·ªÉ t·∫£i l√™n file c·ªßa ri√™ng b·∫°n."
)
template_file = None
if template_option == "Template t√πy ch·ªânh":
    template_file = st.file_uploader("T·∫£i l√™n file template .docx c·ªßa b·∫°n", type=["docx"])

st.subheader("3. Th√¥ng tin c∆° b·∫£n (b·∫Øt bu·ªôc)")
if template_option == "Template t√πy ch·ªânh":
    st.info(
        "üîî **Template t√πy ch·ªânh** c·∫ßn c√≥ c√°c bi·∫øn sau (kh√¥ng k√®m m√¥ t·∫£ `{# ... #}`): "
        "`{{TenCuocHop}}`, `{{ThoiGianCuocHop}}`, `{{DiaDiemCuocHop}}`, `{{TenChuTri}}`, `{{TenThuKy}}`."
    )
else:
    st.caption("C√°c tr∆∞·ªùng b·∫Øt bu·ªôc ƒë√£ c√≥ s·∫µn trong Template VPI (s·∫Ω ƒë∆∞·ª£c ghi ƒë√® b·∫±ng input b·∫°n nh·∫≠p).")

col1, col2 = st.columns(2)
with col1:
    meeting_name      = st.text_input("T√™n cu·ªôc h·ªçp")
    meeting_time      = st.text_input("Th·ªùi gian cu·ªôc h·ªçp (VD: 10/9/2025)")
    meeting_location  = st.text_input("ƒê·ªãa ƒëi·ªÉm cu·ªôc h·ªçp")
with col2:
    meeting_chair     = st.text_input("T√™n ch·ªß tr√¨")
    meeting_secretary = st.text_input("T√™n th∆∞ k√Ω")

recipient_email = st.text_input("4. Email nh·∫≠n k·∫øt qu·∫£ c·ªßa b·∫°n (b·∫Øt bu·ªôc)")

# N√∫t ch·∫°y
if st.button("üöÄ T·∫°o bi√™n b·∫£n", type="primary"):
    default_path = "2025.VPI_BB hop 2025 1.docx"

    # 1) Ki·ªÉm tra b·∫Øt bu·ªôc
    if not validate_inputs(
        template_option=template_option,
        transcript_file=transcript_file,
        template_file=template_file,
        meeting_name=meeting_name,
        meeting_time=meeting_time,
        meeting_location=meeting_location,
        meeting_chair=meeting_chair,
        meeting_secretary=meeting_secretary,
        recipient_email=recipient_email,
        default_template_path=default_path
    ):
        st.stop()

    # 2) X√°c ƒë·ªãnh template
    template_source = None
    if template_option == "Template VPI":
        template_source = ensure_template_path(default_path)
        if not template_source:
            st.stop()
    else:
        template_source = template_file

    # 2.1) Chu·∫©n v·ªÅ BytesIO (ƒë·ªÉ d√πng nhi·ªÅu l·∫ßn)
    template_stream = to_bytesio(template_source)

    with st.spinner("‚è≥ H·ªá th·ªëng ƒëang x·ª≠ l√Ω..."):
        try:
            st.info("1/5 - ƒê·ªçc transcript (.docx) b·∫±ng Docling (fallback python-docx)...")
            transcript_markdown = extract_transcript_markdown(transcript_file)

            st.info("2/5 - Tr√≠ch placeholders t·ª´ template...")
            p_stream_for_extract = io.BytesIO(template_stream.getvalue())
            placeholders = extract_vars_and_desc(p_stream_for_extract)

            # Ki·ªÉm tra placeholders b·∫Øt bu·ªôc v·ªõi template t√πy ch·ªânh
            missing_ph = []
            if template_option == "Template t√πy ch·ªânh":
                try:
                    p_stream_for_scan = io.BytesIO(template_stream.getvalue())
                    tdoc = Document(p_stream_for_scan)
                    ttext = "\n".join([p.text for p in tdoc.paragraphs])
                    for ph in REQUIRED_PLACEHOLDERS:
                        if f"{{{{{ph}}}}}" not in ttext:
                            missing_ph.append(ph)
                except Exception:
                    pass
                if missing_ph:
                    st.error("‚ùå **Template t√πy ch·ªânh thi·∫øu c√°c bi·∫øn b·∫Øt bu·ªôc**: " + ", ".join(missing_ph) +
                             ".\nVui l√≤ng c·∫≠p nh·∫≠t template r·ªìi ch·∫°y l·∫°i.")
                    st.stop()

            st.info("3/5 - Chu·∫©n ho√° attendance (n·∫øu c√≥)...")
            attendance_markdown = ""
            if attendance_file is not None:
                attendance_markdown = attendance_file_to_markdown(attendance_file)

            st.info("4/5 - G·ªçi AI ƒë·ªÉ tr√≠ch xu·∫•t n·ªôi dung (h·ª£p nh·∫•t transcript + attendance)...")
            llm_result = call_gemini_model(transcript_markdown, placeholders, attendance_markdown)

            if llm_result:
                # Ghi ƒë√® c√°c tr∆∞·ªùng b·∫Øt bu·ªôc b·∫±ng input tay
                manual_inputs = {
                    'TenCuocHop':       meeting_name,
                    'ThoiGianCuocHop':  meeting_time,
                    'DiaDiemCuocHop':   meeting_location,
                    'TenChuTri':        meeting_chair,
                    'TenThuKy':         meeting_secretary
                }
                llm_result.update(manual_inputs)

                st.info("5/5 - ƒêi·ªÅn template v√† t·∫°o file Word...")
                p_stream_for_fill = io.BytesIO(template_stream.getvalue())
                docx_buffer = fill_template_to_buffer(p_stream_for_fill, llm_result)
                if docx_buffer:
                    st.success("‚úÖ T·∫°o bi√™n b·∫£n th√†nh c√¥ng!")
                    st.download_button(
                        "‚¨áÔ∏è T·∫£i v·ªÅ bi√™n b·∫£n",
                        data=docx_buffer,
                        file_name="Bien_ban_cuoc_hop.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                    if recipient_email:
                        if send_email_with_attachment(recipient_email, docx_buffer, filename="Bien_ban_cuoc_hop.docx"):
                            st.success("‚úâÔ∏è ƒê√£ g·ª≠i bi√™n b·∫£n t·ªõi email c·ªßa b·∫°n.")
                else:
                    st.error("Kh√¥ng th·ªÉ t·∫°o file Word. Vui l√≤ng ki·ªÉm tra l·∫°i file template.")
            else:
                st.error("Kh√¥ng th·ªÉ l·∫•y k·∫øt qu·∫£ t·ª´ AI. Vui l√≤ng th·ª≠ l·∫°i.")
        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")
