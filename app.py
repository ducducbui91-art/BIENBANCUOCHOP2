# app_refactored.py
# -*- coding: utf-8 -*-
"""
·ª®ng d·ª•ng Streamlit t·∫°o bi√™n b·∫£n cu·ªôc h·ªçp t·ª´ transcript (.docx) + CSV th√†nh vi√™n tham d·ª±.
- Refactor m√£ g·ªëc th√†nh c√°c h√†m r√µ r√†ng, d·ªÖ test, d·ªÖ t√°i s·ª≠ d·ª•ng.
- B·ªï sung ƒë·∫ßu v√†o .csv ƒë·ªÉ k·∫øt h·ª£p v·ªõi transcript tr∆∞·ªõc khi g·ª≠i sang AI.

Y√™u c·∫ßu th∆∞ vi·ªán (requirements.txt):
    streamlit
    pandas
    python-docx
    google-generativeai
    openpyxl   # (ƒë·ªçc Excel n·∫øu c·∫ßn trong t∆∞∆°ng lai)

C√°ch ch·∫°y (local):
    streamlit run app_refactored.py

C·∫•u tr√∫c logic ch√≠nh:
  1) Upload transcript .docx + CSV th√†nh vi√™n + ch·ªçn template .docx
  2) Tr√≠ch placeholders t·ª´ template
  3) ƒê·ªçc transcript + CSV ‚Üí t·∫°o participants_hint
  4) G·ªçi AI t·∫°o JSON theo placeholders (∆∞u ti√™n d√πng CSV cho tr∆∞·ªùng li√™n quan th√†nh vi√™n)
  5) Ghi ƒë√® m·ªôt s·ªë tr∆∞·ªùng th·ªß c√¥ng (T√™n cu·ªôc h·ªçp, Ch·ªß tr√¨, Th∆∞ k√Ω...)
  6) ƒêi·ªÅn template ‚Üí .docx ‚Üí cho t·∫£i xu·ªëng v√†/ho·∫∑c g·ª≠i email
"""

from __future__ import annotations
import io
import os
import re
import json
import zipfile
import ssl
import smtplib
from typing import Dict, List, Optional, Tuple

import streamlit as st
import pandas as pd
from docx import Document
from docx.oxml import OxmlElement
from docx.text.paragraph import Paragraph
from docx.shared import Inches  # noqa: F401 (ƒë·ªÉ s·∫µn n·∫øu sau n√†y c·∫ßn ch√®n ·∫£nh)
import google.generativeai as genai

# =========================
# C·∫§U H√åNH B·∫¢O M·∫¨T / API
# =========================
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    APP_EMAIL      = st.secrets["APP_EMAIL"]
    APP_PASSWORD   = st.secrets["APP_PASSWORD"]
except Exception:
    st.warning("Kh√¥ng t√¨m th·∫•y Streamlit Secrets. ƒêang d√πng c·∫•u h√¨nh local th·ª≠ nghi·ªám!")
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "YOUR_GEMINI_API_KEY")
    APP_EMAIL      = os.getenv("APP_EMAIL", "your_email@example.com")
    APP_PASSWORD   = os.getenv("APP_PASSWORD", "your_app_or_email_password")

try:
    genai.configure(api_key=GEMINI_API_KEY)
except Exception as e:
    st.error(f"L·ªói c·∫•u h√¨nh Gemini API: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i API Key.")

# =========================
# H·∫∞NG S·ªê & REGEX PH·ª§ TR·ª¢
# =========================
COMMENT_RE     = re.compile(r"\{#.*?#\}")                # 1-run
COMMENT_ALL_RE = re.compile(r"\{#.*?#\}", re.DOTALL)     # ƒëa-run
BOLD_RE        = re.compile(r"\*\*(.*?)\*\*")          # **bold**
TOKEN_RE       = re.compile(r"\{\{([^{}]+)\}\}")       # {{Key}}

# =========================
# UTILITIES: WORD/Paragraph
# =========================

def _is_md_table(text: str) -> bool:
    lines = [l.strip() for l in (text or "").strip().splitlines() if l.strip()]
    return (
        len(lines) >= 2
        and "|" in lines[0]
        and set(lines[1].replace(" ", "").replace(":", "")) <= set("-|")
    )


def _parse_md_table(text: str) -> Tuple[List[str], List[List[str]]]:
    lines  = [l.strip() for l in (text or "").strip().splitlines() if l.strip()]
    header = [c.strip() for c in lines[0].split("|")]
    if header and header[0] == "":
        header = header[1:]
    if header and header[-1] == "":
        header = header[:-1]
    rows: List[List[str]] = []
    for ln in lines[2:]:  # Skip header + separator
        cols = [c.strip() for c in ln.split("|")]
        if cols and cols[0] == "":
            cols = cols[1:]
        if cols and cols[-1] == "":
            cols = cols[:-1]
        if cols:
            while len(cols) > len(header):
                cols.pop()
            while len(cols) < len(header):
                cols.append("")
            rows.append(cols)
    return header, rows


def _insert_paragraph_after(anchor_para: Paragraph, style: Optional[str] = None) -> Paragraph:
    new_p_ox = OxmlElement("w:p")
    anchor_para._p.addnext(new_p_ox)
    new_para = Paragraph(new_p_ox, anchor_para._parent)
    if style:
        try:
            new_para.style = style
        except Exception:
            pass
    return new_para


def add_formatted_text(paragraph: Paragraph, text: str, style_info: Optional[dict] = None) -> None:
    parts   = BOLD_RE.split(text or "")
    is_bold = False
    for part in parts:
        if part == "":
            is_bold = not is_bold
            continue
        lines = part.split("\n")
        for i, ln in enumerate(lines):
            if i > 0:
                paragraph.add_run().add_break()
            if ln == "":
                continue
            run = paragraph.add_run(ln)
            if style_info:
                try:
                    f = run.font
                    if style_info.get("size"):
                        f.size = style_info["size"]
                    if style_info.get("name"):
                        f.name = style_info["name"]
                    if style_info.get("bold") is not None:
                        f.bold = style_info["bold"]
                    if style_info.get("italic") is not None:
                        f.italic = style_info["italic"]
                except Exception:
                    pass
            run.bold = run.bold or is_bold
        is_bold = not is_bold


def _concat_runs(paragraph: Paragraph) -> Tuple[str, List[Tuple]]:
    meta, pos, buf = [], 0, []
    for r in paragraph.runs:
        t = r.text or ""
        start, end = pos, pos + len(t)
        meta.append((r, start, end))
        buf.append(t)
        pos = end
    return "".join(buf), meta


def _insert_table_after(paragraph: Paragraph, header: List[str], rows: List[List[str]], table_style: str = "New Table") -> None:
    if not header or not rows:
        return
    body = paragraph._parent
    tbl  = body.add_table(rows=len(rows)+1, cols=len(header))
    try:
        tbl.style = table_style
    except Exception:
        pass
    for i, h in enumerate(header):
        try:
            tbl.rows[0].cells[i].text = str(h)
        except Exception:
            pass
    for r_idx, row in enumerate(rows, start=1):
        for c_idx, cell_val in enumerate(row):
            try:
                tbl.rows[r_idx].cells[c_idx].text = str(cell_val)
            except Exception:
                pass
    paragraph._p.addnext(tbl._tbl)


# =========================
# WORD TEMPLATE PROCESSING
# =========================

def extract_vars_and_desc(docx_file_or_buffer) -> Dict[str, str]:
    """Tr√≠ch xu·∫•t {placeholder: m√¥ t·∫£} t·ª´ .docx (body/header/footer)."""
    xml_parts: List[str] = []
    with zipfile.ZipFile(docx_file_or_buffer) as z:
        for name in z.namelist():
            if name.startswith("word/") and name.endswith(".xml"):
                xml_parts.append(z.read(name).decode("utf8"))
    all_xml = "\n".join(xml_parts)
    texts = re.findall(r"<w:t[^>]*>(.*?)</w:t>", all_xml, flags=re.DOTALL)
    full_text = "".join(texts)
    pattern = re.compile(r"\{\{\s*([A-Za-z0-9_]+)\s*\}\}\s*\{#\s*(.*?)\s*#\}", flags=re.DOTALL)
    return dict(pattern.findall(full_text))


def replace_in_paragraph(paragraph: Paragraph, data: Dict[str, str]) -> None:
    if not paragraph.runs:
        return
    full_text, meta = _concat_runs(paragraph)
    if not full_text:
        return

    items = []
    for m in COMMENT_ALL_RE.finditer(full_text):
        items.append(("comment", m.start(), m.end(), None))
    for m in TOKEN_RE.finditer(full_text):
        key = (m.group(1) or "").strip()
        if key in data:
            items.append(("token", m.start(), m.end(), key))

    if not items:
        for r in paragraph.runs:
            if r.text and COMMENT_RE.search(r.text):
                r.text = COMMENT_RE.sub("", r.text)
        return

    items.sort(key=lambda x: x[1], reverse=True)

    bullet_queue: List[Tuple[str, str]] = []  # (text, style)
    table_queue:  List[Tuple[List[str], List[List[str]]]] = []

    for item_type, start, end, key in items:
        run_start_idx = next((i for i, (_, s, e) in enumerate(meta) if s <= start < e), None)
        run_end_idx   = next((i for i, (_, s, e) in enumerate(meta) if s <  end <= e), None)
        if run_start_idx is None or run_end_idx is None:
            continue

        run_start, s0, e0 = meta[run_start_idx]
        run_end,   s1, e1 = meta[run_end_idx]
        offset_start = start - s0
        offset_end   = end   - s1

        if item_type == "comment":
            if run_start_idx == run_end_idx:
                t = run_start.text or ""
                run_start.text = t[:offset_start] + t[offset_end:]
            else:
                run_start.text = (run_start.text or "")[:offset_start]
                for i in range(run_start_idx + 1, run_end_idx):
                    meta[i][0].text = ""
                run_end.text = (run_end.text or "")[offset_end:]
            continue

        # token {{key}}
        value = data.get(key, "")

        if isinstance(value, str) and _is_md_table(value):
            try:
                header, rows = _parse_md_table(value)
                table_queue.append((header, rows))
                if run_start_idx == run_end_idx:
                    t = run_start.text or ""
                    run_start.text = t[:offset_start] + t[offset_end:]
                else:
                    run_start.text = (run_start.text or "")[:offset_start]
                    for i in range(run_start_idx + 1, run_end_idx):
                        meta[i][0].text = ""
                    run_end.text = (run_end.text or "")[offset_end:]
                continue
            except Exception:
                value = str(value)

        if isinstance(value, str) and any(line.strip().startswith(("-", "+")) for line in value.splitlines()):
            for line in value.splitlines():
                s = line.strip()
                if s.startswith("-"):
                    bullet_queue.append((s[1:].strip(), "List Bullet"))
                elif s.startswith("+"):
                    bullet_queue.append((s[1:].strip(), "List Bullet 2"))
            if run_start_idx == run_end_idx:
                t = run_start.text or ""
                run_start.text = t[:offset_start] + t[offset_end:]
            else:
                run_start.text = (run_start.text or "")[:offset_start]
                for i in range(run_start_idx + 1, run_end_idx):
                    meta[i][0].text = ""
                run_end.text = (run_end.text or "")[offset_end:]
            continue

        replacement_text = str(value)
        if run_start_idx == run_end_idx:
            t = run_start.text or ""
            run_start.text = t[:offset_start] + replacement_text + t[offset_end:]
        else:
            for i in range(run_start_idx + 1, run_end_idx):
                meta[i][0].text = ""
            start_text = (run_start.text or "")[:offset_start]
            run_start.text = start_text + replacement_text
            run_end.text = (run_end.text or "")[offset_end:]

    if bullet_queue or table_queue:
        current_para = paragraph
        for text, style in bullet_queue:
            current_para = _insert_paragraph_after(current_para, style=style)
            add_formatted_text(current_para, text)
        for header, rows in table_queue:
            try:
                _insert_table_after(current_para, header, rows)
            except Exception as e:
                print(f"Error inserting table: {e}")


def fill_template_to_buffer(template_file_or_path, data_input: Dict[str, str]) -> Optional[io.BytesIO]:
    try:
        doc = Document(template_file_or_path)
    except Exception as e:
        st.error(f"L·ªói m·ªü template: {e}")
        return None

    for i, paragraph in enumerate(doc.paragraphs):
        try:
            replace_in_paragraph(paragraph, data_input)
        except Exception as e:
            print(f"Error processing paragraph {i}: {e}")

    for table_idx, table in enumerate(doc.tables):
        for row_idx, row in enumerate(table.rows):
            for cell_idx, cell in enumerate(row.cells):
                for para_idx, paragraph in enumerate(cell.paragraphs):
                    try:
                        replace_in_paragraph(paragraph, data_input)
                    except Exception as e:
                        print(f"Error processing table {table_idx}, row {row_idx}, cell {cell_idx}, paragraph {para_idx}: {e}")

    for section in doc.sections:
        if section.header:
            for paragraph in section.header.paragraphs:
                try:
                    replace_in_paragraph(paragraph, data_input)
                except Exception as e:
                    print(f"Error processing header paragraph: {e}")
        if section.footer:
            for paragraph in section.footer.paragraphs:
                try:
                    replace_in_paragraph(paragraph, data_input)
                except Exception as e:
                    print(f"Error processing footer paragraph: {e}")

    try:
        buf = io.BytesIO()
        doc.save(buf)
        buf.seek(0)
        return buf
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói khi t·∫°o file Word: {e}")
        return None


# =========================
# CSV PARSER: TH√ÄNH VI√äN
# =========================

def _normalize(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s2 = s.strip().lower()
    # b·ªè d·∫•u ti·∫øng Vi·ªát ƒë∆°n gi·∫£n
    rep = {
        "√†": "a", "√°": "a", "·∫£": "a", "√£": "a", "·∫°": "a",
        "ƒÉ": "a", "·∫±": "a", "·∫Ø": "a", "·∫≥": "a", "·∫µ": "a", "·∫∑": "a",
        "√¢": "a", "·∫ß": "a", "·∫•": "a", "·∫©": "a", "·∫´": "a", "·∫≠": "a",
        "√®": "e", "√©": "e", "·∫ª": "e", "·∫Ω": "e", "·∫π": "e",
        "√™": "e", "·ªÅ": "e", "·∫ø": "e", "·ªÉ": "e", "·ªÖ": "e", "·ªá": "e",
        "√¨": "i", "√≠": "i", "·ªâ": "i", "ƒ©": "i", "·ªã": "i",
        "√≤": "o", "√≥": "o", "·ªè": "o", "√µ": "o", "·ªç": "o",
        "√¥": "o", "·ªì": "o", "·ªë": "o", "·ªï": "o", "·ªó": "o", "·ªô": "o",
        "∆°": "o", "·ªù": "o", "·ªõ": "o", "·ªü": "o", "·ª°": "o", "·ª£": "o",
        "√π": "u", "√∫": "u", "·ªß": "u", "≈©": "u", "·ª•": "u",
        "∆∞": "u", "·ª´": "u", "·ª©": "u", "·ª≠": "u", "·ªØ": "u", "·ª±": "u",
        "·ª≥": "y", "√Ω": "y", "·ª∑": "y", "·ªπ": "y", "·ªµ": "y",
        "ƒë": "d",
    }
    for a, b in rep.items():
        s2 = s2.replace(a, b)
    return s2


def _first_match(cols: List[str], candidates: List[str]) -> Optional[str]:
    cols_norm = {c: _normalize(c) for c in cols}
    for c in candidates:
        for col, norm in cols_norm.items():
            if c in norm:
                return col
    return None


def _looks_present(val) -> bool:
    if val is None:
        return True  # n·∫øu kh√¥ng c√≥ c·ªôt th√¨ m·∫∑c ƒë·ªãnh c√≥ m·∫∑t
    s = str(val).strip().lower()
    return s in {"1", "x", "‚úì", "yes", "y", "true", "present", "co", "c√≥", "tham du", "attended"}


def parse_attendance_csv(file) -> Dict[str, str]:
    """ƒê·ªçc CSV v√† tr·∫£ v·ªÅ:
    {
      'participants_bullets': "+ Name ‚Äî Ch·ª©c v·ª•, ƒê∆°n v·ªã (email)\n+ ...",
      'participants_table_md': "|Name|Title|Dept|Email|\n|---|---|---|---|\n|...|...|...|...|"
    }
    """
    df = pd.read_csv(file)
    if df.empty:
        return {"participants_bullets": "", "participants_table_md": ""}

    cols = list(df.columns)
    name_col = _first_match(cols, ["name", "full name", "fullname", "ho va ten", "ho ten", "ten", "hova ten", "ho-va-ten", "hvt", "h·ªç v√† t√™n"])
    dept_col = _first_match(cols, ["don vi", "phong ban", "department", "unit", "division"])
    title_col= _first_match(cols, ["chuc vu", "title", "position", "role"])
    mail_col = _first_match(cols, ["email", "mail"])
    att_col  = _first_match(cols, ["attendance", "status", "co mat", "tham du", "present", "attended"])

    # L·ªçc h√†ng c√≥ m·∫∑t (n·∫øu c√≥ c·ªôt attendance)
    if att_col:
        df = df[df[att_col].apply(_looks_present)]

    # T·∫°o bullets c·∫•p 2 theo y√™u c·∫ßu template VPI
    bullet_lines: List[str] = []
    for _, r in df.iterrows():
        parts = []
        name = str(r.get(name_col, "")).strip()
        if name:
            parts.append(name)
        title = str(r.get(title_col, "")).strip()
        dept  = str(r.get(dept_col,  "")).strip()
        email = str(r.get(mail_col,  "")).strip()
        tail_bits = []
        if title:
            tail_bits.append(title)
        if dept:
            tail_bits.append(dept)
        tail = ", ".join(tail_bits)
        shown = name
        if tail:
            shown += f" ‚Äî {tail}"
        if email:
            shown += f" ({email})"
        if shown:
            bullet_lines.append(f"+ {shown}")

    participants_bullets = "\n".join(bullet_lines)

    # T·∫°o b·∫£ng markdown (d√πng c√°c c·ªôt c√≤n l·∫°i n·∫øu c√≥)
    headers = []
    rows = []
    def add_hdr(h):
        if h not in headers:
            headers.append(h)

    if name_col: add_hdr("Name")
    if title_col: add_hdr("Title/Position")
    if dept_col: add_hdr("Department")
    if mail_col: add_hdr("Email")

    if headers:
        for _, r in df.iterrows():
            row = []
            if name_col: row.append(str(r.get(name_col, "")).strip())
            if title_col: row.append(str(r.get(title_col, "")).strip())
            if dept_col: row.append(str(r.get(dept_col, "")).strip())
            if mail_col: row.append(str(r.get(mail_col, "")).strip())
            rows.append(row)
        # markdown table
        sep = "|" + "|".join(["---" for _ in headers]) + "|"
        participants_table_md = "|" + "|".join(headers) + "|\n" + sep + "\n" + "\n".join(["|" + "|".join(r) + "|" for r in rows])
    else:
        participants_table_md = ""

    return {
        "participants_bullets": participants_bullets,
        "participants_table_md": participants_table_md,
    }


# =========================
# H·ªñ TR·ª¢ ƒê·ªåC CSV/XLSX
# =========================

def read_attendance_to_df(file) -> pd.DataFrame:
    """C·ªë g·∫Øng ƒë·ªçc file attendance d∆∞·ªõi d·∫°ng Excel ho·∫∑c CSV.
    - ∆Øu ti√™n detect theo ph·∫ßn m·ªü r·ªông file.name
    - N·∫øu l√† CSV: th·ª≠ nhi·ªÅu encoding.
    """
    name = getattr(file, "name", "") or ""
    ext = os.path.splitext(name.lower())[1]

    # N·∫øu l√† Excel
    if ext in (".xlsx", ".xls"):
        try:
            return pd.read_excel(file)
        except Exception:
            # N·∫øu ƒë·ªçc Excel th·∫•t b·∫°i, th·ª≠ quay l·∫°i ƒë·∫ßu v√† ƒë·ªçc d·∫°ng CSV (edge case export sai MIME)
            try:
                file.seek(0)
            except Exception:
                pass

    # Th·ª≠ ƒë·ªçc CSV v·ªõi nhi·ªÅu encoding
    encodings = ["utf-8", "utf-8-sig", "cp1258", "latin1"]
    last_err = None
    for enc in encodings:
        try:
            file.seek(0)
        except Exception:
            pass
        try:
            return pd.read_csv(file, encoding=enc)
        except Exception as e:
            last_err = e
            continue

    # Th·ª≠ ch·ªët: n·∫øu l√† Excel th·∫≠t s·ª± nh∆∞ng kh√¥ng c√≥ ph·∫ßn m·ªü r·ªông
    try:
        file.seek(0)
    except Exception:
        pass
    try:
        return pd.read_excel(file)
    except Exception as e:
        raise RuntimeError(f"Kh√¥ng th·ªÉ ƒë·ªçc file Attendance (CSV/Excel). L·ªói cu·ªëi: {last_err or e}")


def _attendance_df_to_struct(df: pd.DataFrame) -> Dict[str, str]:
    if df is None or df.empty:
        return {"participants_bullets": "", "participants_table_md": ""}

    cols = list(df.columns)
    name_col = _first_match(cols, ["name", "full name", "fullname", "ho va ten", "ho ten", "ten", "hova ten", "ho-va-ten", "hvt", "h·ªç v√† t√™n"])
    dept_col = _first_match(cols, ["don vi", "phong ban", "department", "unit", "division"])
    title_col= _first_match(cols, ["chuc vu", "title", "position", "role"])
    mail_col = _first_match(cols, ["email", "mail"])
    att_col  = _first_match(cols, ["attendance", "status", "co mat", "tham du", "present", "attended"])

    if att_col:
        df = df[df[att_col].apply(_looks_present)]

    bullet_lines: List[str] = []
    for _, r in df.iterrows():
        parts = []
        name = str(r.get(name_col, "")).strip()
        if name:
            parts.append(name)
        title = str(r.get(title_col, "")).strip()
        dept  = str(r.get(dept_col,  "")).strip()
        email = str(r.get(mail_col,  "")).strip()
        tail_bits = []
        if title:
            tail_bits.append(title)
        if dept:
            tail_bits.append(dept)
        tail = ", ".join(tail_bits)
        shown = name
        if tail:
            shown += f" ‚Äî {tail}"
        if email:
            shown += f" ({email})"
        if shown:
            bullet_lines.append(f"+ {shown}")

    participants_bullets = "".join(bullet_lines)

    headers = []
    rows = []
    def add_hdr(h):
        if h not in headers:
            headers.append(h)

    if name_col: add_hdr("Name")
    if title_col: add_hdr("Title/Position")
    if dept_col: add_hdr("Department")
    if mail_col: add_hdr("Email")

    if headers:
        for _, r in df.iterrows():
            row = []
            if name_col: row.append(str(r.get(name_col, "")).strip())
            if title_col: row.append(str(r.get(title_col, "")).strip())
            if dept_col: row.append(str(r.get(dept_col, "")).strip())
            if mail_col: row.append(str(r.get(mail_col, "")).strip())
            rows.append(row)
        sep = "|" + "|".join(["---" for _ in headers]) + "|"
        participants_table_md = "|" + "|".join(headers) + "|" + sep + "" + "".join(["|" + "|".join(r) + "|" for r in rows])
    else:
        participants_table_md = ""

    return {
        "participants_bullets": participants_bullets,
        "participants_table_md": participants_table_md,
    }


def parse_attendance_any(file) -> Dict[str, str]:
    """API h·ª£p nh·∫•t: nh·∫≠n file CSV/XLSX v√† tr·∫£ v·ªÅ c·∫•u tr√∫c bullets + b·∫£ng markdown."""
    df = read_attendance_to_df(file)
    return _attendance_df_to_struct(df)

# =========================
# LLM CALL (Gemini)
# =========================

def call_gemini_model(transcript_content: str, placeholders: Dict[str, str], participants_hint: Dict[str, str] | None = None) -> Optional[Dict[str, str]]:
    model = genai.GenerativeModel("gemini-2.5-pro")

    # Chu·∫©n b·ªã ph·∫ßn d·ªØ li·ªáu CSV cho prompt
    participants_block = ""
    if participants_hint:
        blt = participants_hint.get("participants_bullets", "").strip()
        tbl = participants_hint.get("participants_table_md", "").strip()
        participants_block = f"""
# D·ªØ li·ªáu CSV th√†nh vi√™n (∆∞u ti√™n s·ª≠ d·ª•ng khi ƒëi·ªÅn c√°c tr∆∞·ªùng li√™n quan ng∆∞·ªùi tham d·ª±)
- **Bullet c·∫•p 2 (∆∞u ti√™n cho {{ThanhPhanThamGia}} n·∫øu c√≥ trong placeholders):**\n{blt}
- **B·∫£ng Markdown (n·∫øu c·∫ßn):**\n{tbl}
""".strip()

    # Prompt (k·∫ø th·ª´a & m·ªü r·ªông t·ª´ app g·ªëc)
    Prompt_word = f"""
# Vai tr√≤
B·∫°n l√† tr·ª£ l√Ω AI chuy√™n nghi·ªáp, nhi·ªám v·ª•: tr√≠ch xu·∫•t/th·ªÉ hi·ªán n·ªôi dung cho bi√™n b·∫£n cu·ªôc h·ªçp t·ª´ transcript **v√†** d·ªØ li·ªáu CSV ng∆∞·ªùi tham d·ª± (n·∫øu c√≥), ƒë·∫£m b·∫£o ch√≠nh x√°c v√† tr√¨nh b√†y chu·∫©n m·ª±c.

# ƒê·∫ßu v√†o
1) **B·∫£n ghi cu·ªôc h·ªçp (transcript):** ```{transcript_content}```
2) **Danh s√°ch placeholders c·∫ßn ƒëi·ªÅn** (dict: key = t√™n tr∆∞·ªùng, value = m√¥ t·∫£/ƒë·ªãnh d·∫°ng y√™u c·∫ßu): ```{json.dumps(placeholders, ensure_ascii=False)}```
3) **D·ªØ li·ªáu CSV v·ªÅ th√†nh vi√™n** (n·∫øu c√≥):
{participants_block}

# Y√™u c·∫ßu quan tr·ªçng
- **Lu√¥n tr·∫£ v·ªÅ ti·∫øng Vi·ªát**.
- **Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON**: keys **tr√πng 100%** t√™n placeholders; values **ch·ªâ l√† chu·ªói** (string). **Kh√¥ng** th√™m/b·ªõt key, kh√¥ng l·ªìng c·∫•u tr√∫c.
- **Tu√¢n th·ªß ch·∫∑t ch·∫Ω ƒë·ªãnh d·∫°ng** ghi trong m√¥ t·∫£ c·ªßa t·ª´ng placeholder (bullet 1: b·∫Øt ƒë·∫ßu b·∫±ng "- ", bullet 2: b·∫Øt ƒë·∫ßu b·∫±ng "+ ", b·∫£ng: Markdown...).
- **∆Øu ti√™n s·ª≠ d·ª•ng d·ªØ li·ªáu CSV** ƒë·ªÉ ƒëi·ªÅn c√°c tr∆∞·ªùng v·ªÅ **th√†nh ph·∫ßn tham gia**, **vai tr√≤/ph·ª• tr√°ch**. N·∫øu transcript c≈©ng c√≥ th√¥ng tin, **k·∫øt h·ª£p h·ª£p l√Ω**.
- N·∫øu thi·∫øu th√¥ng tin: ghi ƒë√∫ng chu·ªói **"Ch∆∞a c√≥ th√¥ng tin"**.

# K·∫øt qu·∫£
- Xu·∫•t **m·ªôt chu·ªói JSON h·ª£p l·ªá duy nh·∫•t** theo ƒë√∫ng quy t·∫Øc tr√™n.
"""

    try:
        response = model.generate_content(
            contents=Prompt_word,
            generation_config={"response_mime_type": "application/json"}
        )
        if response and hasattr(response, "text"):
            raw = response.text.strip()
            if raw.startswith("```"):
                raw = raw.split("```")[1].strip("json\n")
            return json.loads(raw)
        else:
            st.error("Ph·∫£n h·ªìi t·ª´ Gemini API b·ªã thi·∫øu ho·∫∑c kh√¥ng h·ª£p l·ªá.")
            return None
    except Exception as e:
        st.error(f"L·ªói khi g·ªçi Gemini API: {e}")
        return None


# =========================
# EMAIL SENDER
# =========================

def send_email_with_attachment(recipient_email: str, attachment_buffer: io.BytesIO, filename: str = "Bien_ban_cuoc_hop.docx") -> bool:
    SMTP_SERVER = "smtp.office365.com"
    SMTP_PORT = 587

    from email.message import EmailMessage

    msg = EmailMessage()
    msg["Subject"] = "Bi√™n b·∫£n cu·ªôc h·ªçp ƒë√£ ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông"
    msg["From"] = APP_EMAIL
    msg["To"] = recipient_email
    msg.set_content(
        "Ch√†o b·∫°n,\n\nBi√™n b·∫£n cu·ªôc h·ªçp ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng.\nVui l√≤ng xem trong file ƒë√≠nh k√®m.\n\nTr√¢n tr·ªçng,\nC√¥ng c·ª• t·∫°o bi√™n b·∫£n t·ª± ƒë·ªông."
    )
    msg.add_attachment(
        attachment_buffer.getvalue(),
        maintype="application",
        subtype="vnd.openxmlformats-officedocument.wordprocessingml.document",
        filename=filename,
    )

    try:
        ctx = ssl.create_default_context()
        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as s:
            s.starttls(context=ctx)
            s.login(APP_EMAIL, APP_PASSWORD)
            s.send_message(msg)
        return True
    except Exception as e:
        st.error(f"L·ªói khi g·ª≠i email: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh email v√† m·∫≠t kh·∫©u ·ª©ng d·ª•ng.")
        return False


# =========================
# HELPERS (IO/UI)
# =========================

def load_transcript_docx(file) -> str:
    """ƒê·ªçc to√†n b·ªô text t·ª´ .docx transcript."""
    try:
        doc = Document(file)
        return "\n".join([para.text for para in doc.paragraphs])
    except Exception as e:
        st.error(f"L·ªói ƒë·ªçc transcript .docx: {e}")
        return ""


def ensure_template_path(default_filename: str) -> Optional[str]:
    """Tr·∫£ template path n·∫øu t·ªìn t·∫°i, ng∆∞·ª£c l·∫°i c·∫£nh b√°o ng∆∞·ªùi d√πng ch·ªçn custom."""
    if os.path.exists(default_filename):
        return default_filename
    st.error(f"Kh√¥ng t√¨m th·∫•y template m·∫∑c ƒë·ªãnh: {default_filename}. H√£y ch·ªçn 'Template t√πy ch·ªânh' v√† t·∫£i file l√™n.")
    return None


# =========================
# STREAMLIT UI
# =========================

st.set_page_config(layout="wide", page_title="C√¥ng c·ª• t·∫°o Bi√™n b·∫£n cu·ªôc h·ªçp (refactor)")
st.title("üõ†Ô∏è C√¥ng c·ª• t·∫°o bi√™n b·∫£n cu·ªôc h·ªçp t·ª± ƒë·ªông ‚Äî B·∫£n refactor")

with st.sidebar:
    st.info("**H∆∞·ªõng d·∫´n nhanh**")
    st.markdown(
        """
1) T·∫£i **transcript (.docx)** v√† **CSV th√†nh vi√™n**
2) Ch·ªçn **Template VPI** ho·∫∑c **Template t√πy ch·ªânh (.docx)**
3) ƒêi·ªÅn v√†i tr∆∞·ªùng tay (n·∫øu mu·ªën)
4) Nh·∫•n **T·∫°o bi√™n b·∫£n**
        """
    )
    st.caption("Y√™u c·∫ßu th∆∞ vi·ªán ƒë√£ c√≥ trong requirements.txt c·ªßa d·ª± √°n.")

st.subheader("1) Nh·∫≠p d·ªØ li·ªáu ƒë·∫ßu v√†o")
colA, colB = st.columns(2)
with colA:
    transcript_file = st.file_uploader("T·∫£i transcript (.docx)", type=["docx"], key="transcript")
with colB:
    csv_file = st.file_uploader("T·∫£i CSV/Excel th√†nh vi√™n (Attendance)", type=["csv", "xlsx", "xls"], key="csv")

st.subheader("2) L·ª±a ch·ªçn Template")
template_option = st.selectbox(
    "B·∫°n mu·ªën s·ª≠ d·ª•ng lo·∫°i template n√†o?",
    ("Template VPI", "Template t√πy ch·ªânh"),
)

template_file = None
if template_option == "Template t√πy ch·ªânh":
    template_file = st.file_uploader("T·∫£i file template .docx c·ªßa b·∫°n", type=["docx"], key="tpl")

st.subheader("3) Th√¥ng tin c∆° b·∫£n (ghi ƒë√® k·∫øt qu·∫£ AI n·∫øu nh·∫≠p)")
col1, col2 = st.columns(2)
with col1:
    meeting_name      = st.text_input("T√™n cu·ªôc h·ªçp")
    meeting_time      = st.text_input("Th·ªùi gian cu·ªôc h·ªçp (VD: 10/9/2025)")
    meeting_location  = st.text_input("ƒê·ªãa ƒëi·ªÉm cu·ªôc h·ªçp")
with col2:
    meeting_chair     = st.text_input("T√™n ch·ªß tr√¨")
    meeting_secretary = st.text_input("T√™n th∆∞ k√Ω")

recipient_email = st.text_input("4) Email nh·∫≠n k·∫øt qu·∫£ (t√πy ch·ªçn)")

if st.button("üöÄ T·∫°o bi√™n b·∫£n", type="primary"):
    if not transcript_file:
        st.warning("Vui l√≤ng t·∫£i l√™n file transcript .docx")
    else:
        # 1) Ch·ªçn template
        template_to_use = None
        if template_option == "Template VPI":
            # Gi·ªØ t√™n template m·∫∑c ƒë·ªãnh y nh∆∞ repo g·ªëc ƒë·ªÉ t∆∞∆°ng th√≠ch
            default_path = "2025.VPI_BB hop 2025 1.docx"
            template_to_use = ensure_template_path(default_path)
        else:
            template_to_use = template_file

        if not template_to_use:
            st.stop()

        with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω..."):
            try:
                st.info("1/5 - ƒê·ªçc transcript .docx")
                transcript_content = load_transcript_docx(transcript_file)

                st.info("2/5 - Tr√≠ch placeholders t·ª´ template")
                placeholders = extract_vars_and_desc(template_to_use)

                st.info("3/5 - Ph√¢n t√≠ch CSV th√†nh vi√™n")
                participants_hint = {"participants_bullets": "", "participants_table_md": ""}
if csv_file is not None:
    try:
        participants_hint = parse_attendance_any(csv_file)
    except Exception as e:
        st.warning(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c CSV/Excel: {e}")

                st.info("4/5 - G·ªçi AI t·∫°o JSON theo placeholders (k·∫øt h·ª£p transcript + CSV)")
                llm_result = call_gemini_model(transcript_content, placeholders, participants_hint)

                if llm_result:
                    # Ghi ƒë√® c√°c input tay (n·∫øu nh·∫≠p)
                    manual_inputs = {
                        'TenCuocHop':       meeting_name,
                        'ThoiGianCuocHop':  meeting_time,
                        'DiaDiemCuocHop':   meeting_location,
                        'TenChuTri':        meeting_chair,
                        'TenThuKy':         meeting_secretary,
                    }
                    for k, v in manual_inputs.items():
                        if v and k in llm_result:
                            llm_result[k] = v

                    # ∆Øu ti√™n CSV cho th√†nh ph·∫ßn tham gia n·∫øu placeholder t·ªìn t·∫°i
                    if 'ThanhPhanThamGia' in llm_result and participants_hint.get("participants_bullets"):
                        llm_result['ThanhPhanThamGia'] = participants_hint['participants_bullets']

                    st.info("5/5 - ƒêi·ªÅn template v√† t·∫°o file Word")
                    docx_buffer = fill_template_to_buffer(template_to_use, llm_result)
                    if docx_buffer:
                        st.success("‚úÖ T·∫°o bi√™n b·∫£n th√†nh c√¥ng!")
                        st.download_button(
                            "‚¨áÔ∏è T·∫£i v·ªÅ bi√™n b·∫£n",
                            data=docx_buffer,
                            file_name="Bien_ban_cuoc_hop.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        )
                        if recipient_email:
                            ok = send_email_with_attachment(recipient_email, docx_buffer)
                            if ok:
                                st.success("‚úâÔ∏è ƒê√£ g·ª≠i bi√™n b·∫£n t·ªõi email c·ªßa b·∫°n.")
                    else:
                        st.error("Kh√¥ng th·ªÉ t·∫°o file Word. Ki·ªÉm tra l·∫°i template ho·∫∑c d·ªØ li·ªáu ƒë·∫ßu v√†o.")
                else:
                    st.error("AI kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i.")
            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")
